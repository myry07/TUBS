{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with pandas\n",
    "`pandas` introduces a new class: the `DataFrame`. How to create and handle it, is discussed in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data\n",
    "\n",
    "`pandas` has a lot of methods for importing data, e.g. `read_csv`, `read_excel`, `read_html`, ... . We will focus on `read_csv` as it is commonly used for scientific purposes.\n",
    "\n",
    "The most important arguments for `read_csv` are `file_path`, `sep` (symbol separating the data) and `header` (index of the line of the header). Other arguments, like `lineterminator`, `quotechar`, ... are also necessary sometimes.\n",
    "\n",
    "\n",
    "To access the individual columns we write \n",
    "```python\n",
    "df['column_name'] \n",
    "```\n",
    "and can assign it to an own variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = '../data/random_ints.csv'\n",
    "\n",
    "df = pd.read_csv(input_file_name, sep=',', header=0)\n",
    "\n",
    "x = df['x']\n",
    "y = df['y']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple columns can be accessed using `df[[column_name1, column_name2, ...]]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting data\n",
    "To export data, we have to create a Python dictonary using `{}`. If you have data `x` and `y`, the dictionary is initialized via\n",
    "```python\n",
    "dictionary_name = {'column_name1': x, 'column_name2': y}\n",
    "```\n",
    "like shown below (column_names are set to `'x'` and `'y'` in this example).\n",
    "\n",
    "The dictionary can then be turned into a `DataFrame` via `pd.DataFrame(dictionary_name)`.\n",
    "\n",
    "The final step is using `.to_csv(output_file_path, sep=..., index=...)`. `sep` is the symbol that is used for separating the values (`','` in the example below) and the boolean argument `index` is used to decide whether to export the index column (`index=True`, standard value) or not (`index=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = '../data/random_ints.csv'\n",
    "\n",
    "output_dict = {'x': x, 'y': y}\n",
    "\n",
    "output_dataframe = pd.DataFrame(output_dict)\n",
    "\n",
    "output_dataframe.to_csv(output_file_name, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful pandas functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding column to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing randint from random-module for generating random integers.\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using `df['new_colum_name'] = new_data` a new column with the name `new_colum_name` containing the data `new_data` can be added to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [randint(0,10) for i in range(15)]\n",
    "\n",
    "df['z'] = z\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing column from DataFrame\n",
    "To remove the column with the name `column_name` from `df`, we use `df.drop(column_name, axis='columns')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('z', axis='columns')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding row to DataFrame\n",
    "To add a row to the end of a DataFrame, we can initialize a new DataFrame concatenate it with the old DataFrame using the `concat()`-method as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'x': [100], 'y': [100]}\n",
    "new_row = pd.DataFrame(new_row)\n",
    "\n",
    "# Adding to the end\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a row between two rows in the DataFrame `df`, `df.loc` can be used with a float index. \n",
    "\n",
    "`df.loc[index] = new_row` adds the list `new_row` to the end of the dataframe with the index `index`. By sorting the DataFrame by its indeces using `df.sort_index()`, the new row is moved to the right position.\n",
    "\n",
    "Using `.reset_index(drop=True)`, the indeces are newly set as integers. I recommend doing this as we are used to list indeces being integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding at specific position\n",
    "df.loc[2.5] = [200, 200] \n",
    "\n",
    "df = df.sort_index().reset_index(drop=True) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing row from DataFrame\n",
    "Removing rows from a DataFrame is similar to removing columns from a Dataframe. `df.drop(labels=[i, j, ...], axis = 'rows')` removes the rows with the indeces `i, j, ...` from the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=[3,16], axis='rows')\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access data\n",
    "There are multiple possibilities to access specific data points in the dataframe.\n",
    "\n",
    "- Using `.iloc`: `df[column_name].iloc[row_index]` \n",
    "- Using a dummy variable:\n",
    "`arr = list(df[column_name]); print(arr[row_index])`\n",
    "\n",
    "`row_index` is an integer like in an ordinary Python list.\n",
    "\n",
    "- using `.at`: `df.at[index, column_name]`\n",
    "\n",
    "`index` is the value of the index of the row. It can be a float (as shown above) or even a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x'].iloc[1])\n",
    "\n",
    "arr = list(df['x'])\n",
    "print(arr[1])\n",
    "\n",
    "print(df.at[1, 'x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data\n",
    "`pandas` offers a lot of possibilities when it comes to filtering of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter data by it's indices, we can use `df.iloc[start_row:end_row, start_column:end_column]`. Note that `end_row` and `end_column` are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by index\n",
    "filtered_df1 = df.iloc[2:7, 0:2] # second to seventh row, first to second column\n",
    "\n",
    "filtered_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter by giving conditions. Three possibilities are shown here:\n",
    "- `df.query(condition)`: The `condition` is given as a string. Logical operators `and` and `or` are used.\n",
    "- `df[(df.column_name1 < ...) & ...]` or `df.loc[(df.column_name1 < ...) & ...]`: The conditions are formulated using comparison operators and `df.column_name` for the column. Bitwise Logical operators `&` (AND), `|` (OR) and `^` (XOR) are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by condition\n",
    "filtered_df2 = df.query(\"x < 5 and y > 5\")    # condition as string\n",
    "\n",
    "filtered_df2 = df[(df.x < 5) & (df.y > 5)]\n",
    "\n",
    "filtered_df2 = df.loc[(df.x < 5) & (df.y > 5)]\n",
    "\n",
    "filtered_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting by column\n",
    "The `df.sort_values(by = column_name)` method sorts the values of `df` in ascending order by the column `column_name`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics\n",
    "There are multiple functions for doing statistics with pandas. `df.describe()` gives a quick statistical overview of every column of `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())\n",
    "print('')\n",
    "\n",
    "# or alternatively using mean(), std() and var()\n",
    "print(f'mean of df: \\n{df.mean()}\\n')\n",
    "print(f'standard deviation of df: \\n{df.std()}\\n')\n",
    "print(f'variance of df: \\n{df.var()}\\n')\n",
    "print(f'minimum of df: \\n{df.min()}\\n')\n",
    "print(f'maximum of df: \\n{df.max()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicate rows\n",
    "As the name of the function `drop_duplicates` already suggests, `df.drop_duplicates()` removes all duplicate rows from `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'name': ['Alice', 'Bob', 'Charlie', 'Alice'], 'age': [21, 20, 25, 21], 'gender': ['F','M','NB','F']})\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop_duplicates()\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge two DataFrames\n",
    "Sometimes there are multiple DataFrames containing information that can be merged into one DataFrame. In this example, there is a separate DataFrame `new_df_2` containing the professiongs of Alice, Bob and Charlie.\n",
    "\n",
    "By using `pd.merge(new_df, new_df_2)`, the DataFrames `new_df` and `new_df_2` are merged into one DataFrame. Note that the `name`-column only appears once.\n",
    "\n",
    "In a scientific context this can be useful when combining data from different measurement devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_2 = pd.DataFrame({'profession': ['mathematician', 'physicist', 'chemist'], 'name': ['Alice', 'Bob', 'Charlie']})\n",
    "\n",
    "merged_df = pd.merge(new_df, new_df_2)\n",
    "\n",
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
